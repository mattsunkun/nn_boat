###   hot-1/2018_2022-9__2022_10_17_16_05_01   ###
using data: hot-1/2018_2022-9
avoiding curse of dimention
explanatory_size: 77
device: cpu
max epoch: 30
preprocessing time: 1.2592718601226807
1/30  train_loss: 15069.545002043247  train_accuracy: 0.5477888609693985  test_loss: 1.2356750965118408  test_accuracy: 0.5586943831061703
2/30  train_loss: 14771.152090609074  train_accuracy: 0.5539819115544388  test_loss: 1.2203842401504517  test_accuracy: 0.5606910496882324
3/30  train_loss: 14665.012908518314  train_accuracy: 0.5561139453624034  test_loss: 1.2184662818908691  test_accuracy: 0.5602849480105248
4/30  train_loss: 14605.092037856579  train_accuracy: 0.5587874480739782  test_loss: 1.2183932065963745  test_accuracy: 0.5620531823988765
5/30  train_loss: 14543.175076425076  train_accuracy: 0.5589566571063563  test_loss: 1.2221916913986206  test_accuracy: 0.5604203152364273
6/30  train_loss: 14529.509739935398  train_accuracy: 0.5597688604617714  test_loss: 1.2199546098709106  test_accuracy: 0.5601157389781467
7/30  train_loss: 14488.731493413448  train_accuracy: 0.5604287756880463  test_loss: 1.2209237813949585  test_accuracy: 0.5626792558186756
8/30  train_loss: 14469.310095310211  train_accuracy: 0.5612578999466992  test_loss: 1.2194788455963135  test_accuracy: 0.5618332106567848
9/30  train_loss: 14466.603859364986  train_accuracy: 0.5617232247857391  test_loss: 1.2176997661590576  test_accuracy: 0.5618755129148794
10/30  train_loss: 14429.929522037506  train_accuracy: 0.562738478980008  test_loss: 1.2180231809616089  test_accuracy: 0.5629584507220995
11/30  train_loss: 14397.741973251104  train_accuracy: 0.5633899337546638  test_loss: 1.2185713052749634  test_accuracy: 0.5610717700110832
12/30  train_loss: 14394.232997596264  train_accuracy: 0.5630261343350508  test_loss: 1.219723105430603  test_accuracy: 0.5634406964643772
13/30  train_loss: 14378.178052961826  train_accuracy: 0.5629584507220995  test_loss: 1.2198292016983032  test_accuracy: 0.5625015863346785
14/30  train_loss: 14356.255173027515  train_accuracy: 0.5633307105933315  test_loss: 1.2194446325302124  test_accuracy: 0.5628484648510538
15/30  train_loss: 14344.260723114014  train_accuracy: 0.5633476314965693  test_loss: 1.2202309370040894  test_accuracy: 0.5616047784630743
16/30  train_loss: 14336.348891019821  train_accuracy: 0.564016007174463  test_loss: 1.220555067062378  test_accuracy: 0.5624508236249651
17/30  train_loss: 14320.350420176983  train_accuracy: 0.5643882670456949  test_loss: 1.2269121408462524  test_accuracy: 0.557163041363148
18/30  train_loss: 14312.149913311005  train_accuracy: 0.564016007174463  test_loss: 1.222756028175354  test_accuracy: 0.5614440298823151
19/30  train_loss: 14298.288746446371  train_accuracy: 0.5653950607883449  test_loss: 1.2224102020263672  test_accuracy: 0.5607587333011836
20/30  train_loss: 14272.102253645658  train_accuracy: 0.565022800917113  test_loss: 1.2244389057159424  test_accuracy: 0.5619601174310684
21/30  train_loss: 14272.058584749699  train_accuracy: 0.5652343122075857  test_loss: 1.2247810363769531  test_accuracy: 0.5603357107202382
22/30  train_loss: 14246.120027720928  train_accuracy: 0.5655304280142474  test_loss: 1.224448323249817  test_accuracy: 0.5620108801407819
23/30  train_loss: 14241.484405755997  train_accuracy: 0.5651750890462532  test_loss: 1.2255488634109497  test_accuracy: 0.5590581825257832
24/30  train_loss: 14246.384270846844  train_accuracy: 0.5657927020144335  test_loss: 1.22500479221344  test_accuracy: 0.5609787050432752
25/30  train_loss: 14240.329547166824  train_accuracy: 0.565564269820723  test_loss: 1.2293086051940918  test_accuracy: 0.5579583238153253
26/30  train_loss: 14210.675728678703  train_accuracy: 0.566393394079376  test_loss: 1.2256404161453247  test_accuracy: 0.5607418123979458
27/30  train_loss: 14202.109090358019  train_accuracy: 0.567120992918602  test_loss: 1.225167989730835  test_accuracy: 0.5605556824623298
28/30  train_loss: 14200.361396193504  train_accuracy: 0.5662580268534735  test_loss: 1.2276432514190674  test_accuracy: 0.5622308518828735
29/30  train_loss: 14208.97329390049  train_accuracy: 0.5665033799504218  test_loss: 1.2282003164291382  test_accuracy: 0.5605133802042354
30/30  train_loss: 14196.412485301495  train_accuracy: 0.5665372217568974  test_loss: 1.227176308631897  test_accuracy: 0.5613086626564125
training time: 550.4265930652618
save model as: net-weight/hot-1/2018_2022-9__2022_10_17_16_05_01.pth
train loss: 14196.412485301495
test accuracy: 0.5613086626564125
using weathr: [0, 1, 2, '_', 4, 5]
using player: [6, '_', '_', 9, 10, 11, 12, '_', '_', 15, '_', '_', 18, 19, '_', '_', '_', 23, 24, 25, 26]
amount of explanatory variables:77
number of training data:236394 * 0.5 = 118197.0
save picture as: net-weight/hot-1/2018_2022-9__2022_10_17_16_05_01.png

###   hot-1/2018_2022-9__2022_10_17_16_49_53   ###
using data: hot-1/2018_2022-9
avoiding curse of dimention
explanatory_size: 36
device: cpu
max epoch: 10
preprocessing time: 1.0197482109069824
1/10  train_loss: 15299.01554954052  train_accuracy: 0.5428225758690999  test_loss: 1.2667219638824463  test_accuracy: 0.5523236630371329
2/10  train_loss: 15035.363945960999  train_accuracy: 0.5487448920023351  test_loss: 1.2563350200653076  test_accuracy: 0.5489225614863321
3/10  train_loss: 14959.593744516373  train_accuracy: 0.5510545952942968  test_loss: 1.259690523147583  test_accuracy: 0.5517906545851418
4/10  train_loss: 14913.009957969189  train_accuracy: 0.5519598636175199  test_loss: 1.248760461807251  test_accuracy: 0.5535588889734934
5/10  train_loss: 14885.548981010914  train_accuracy: 0.551587603746288  test_loss: 1.2443479299545288  test_accuracy: 0.5544387759418598
6/10  train_loss: 14864.041797697544  train_accuracy: 0.5531443268441669  test_loss: 1.2441786527633667  test_accuracy: 0.5539057674898686
7/10  train_loss: 14853.228286147118  train_accuracy: 0.5525943974889379  test_loss: 1.2492729425430298  test_accuracy: 0.553228931360356
8/10  train_loss: 14826.788236618042  train_accuracy: 0.5536773352961581  test_loss: 1.2454112768173218  test_accuracy: 0.5544979991031921
9/10  train_loss: 14812.546808958054  train_accuracy: 0.5536265725864447  test_loss: 1.2454907894134521  test_accuracy: 0.5534489031024477
10/10  train_loss: 14803.240908265114  train_accuracy: 0.5540834369738656  test_loss: 1.2458471059799194  test_accuracy: 0.5534658240056854
training time: 171.98617005348206
save model as: net-weight/hot-1/2018_2022-9__2022_10_17_16_49_53.pth
train loss: 14803.240908265114
test accuracy: 0.5534658240056854
using weathr: ['_', '_', '_', '_', '_', '_']
using player: [6, '_', '_', '_', '_', 11, '_', '_', '_', '_', '_', '_', 18, '_', '_', '_', '_', 23, 24, 25, '_']
amount of explanatory variables:36
number of training data:236394 * 0.5 = 118197.0
save picture as: net-weight/hot-1/2018_2022-9__2022_10_17_16_49_53.png